\chapter{Introduction}

In cryptography, one of the primary security models we use for reasoning about confidentiality and privacy involves three parties: Alice, Bob, and Eve. Alice and Bob wish to send messages between the two of them. Since their messages are of a private nature, they encrypt them in some way, so that anyone reading the messages is unable to determine what they mean. To illustrate this, we consider the eavesdropper Eve. If Eve is unable to determine significant information about the messages, we say the encryption scheme is secure. This model is very flexible, and a variety of restrictions and capabilities can be given to the parties involved. Using this model, we can follow the methodology of provable security in cryptography to come up with very strong guarantees on the privacy afforded by our encryption scheme, subject to the assumptions we make along the way.

It is important to critically examine all of the assumptions we make when proving cryptography secure in a given model, and we will consider one in particular. An ever-present assumption when applying cryptographic results to real world situations is that the model accurately reflects the real-world situation in which we are implementing our cryptography. In particular, the capabilities and limitations we give the adversary Eve in our model need to accurately reflect the capabilities and intentions of our expected adversaries in the real world. This can easily become a cat-and-mouse game: if an adversary is effectively eavesdropping using a simple technique, which we then mitigate through implementation of a new scheme with a more robust security analysis that precludes that simple technique, will the adversary simply admit defeat? Or will they choose a new technique outside of the model in which we have proved security?

A particular way that an adversary can work outside of most classical security models is by undermining the cryptographic schemes being used. If Alice and Bob believe that they are using a secure encryption scheme, but in reality they are not, then Eve may have an advantage. If Eve is able to maliciously influence Alice and Bob to use an insecure scheme without their knowledge, we would call this undermining cryptography. There are many ways in which this could occur, including the introduction of backdoors \cite{FSE:RijPre97,FSE:Paterson99}, for example. More importantly, there are several instances where the undermining of cryptography may have already occurred. This includes the potential deliberate weakening of DES keys to only 56 bits at the time of standardization \cite{SB1988} and the potential that there was a backdoor implemented in the pseudorandom bit generator Dual\_EC\_DRBG \cite{USENIX:CNEGLRBMSF14}, which was standardized in 2006 despite knowledge of the possibility of the backdoor at the time. After Snowden's revelations of the activities of the National Security Agency (NSA) of the United States in 2013 \cite{snowden}, we know that the NSA has worked to undermine cryptography in the past.

In the presence of adversaries that are willing to work outside of our cryptographic security model by undermining our cryptographic schemes (and are capable of doing so), what are we to do? The ideal solution would be to include such subversion techniques in our model, and re-develop schemes that are once again secure in this model. One way to model such subversion is through Algorithm Substitution Attacks (ASAs). ASAs were first presented by Bellare, Paterson, and Rogaway \cite{C:BelPatRog14}, as a specific case of a class of attacks known as kleptography \cite{C:YouYun96,EC:YouYun97,FSE:YouYun98,SAC:YouYun04,ACISP:YouYun03}. In an ASA on a symmetric encryption scheme, an attacker has the following goal: replace an encryption function with a subverted version, such that, upon observing ciphertexts, the attacker is able to recover the secret key while the user is unable to detect the difference between the subverted and original encryption algorithms. This model captures any method that an attacker might employ to undermine cryptography by modifying the algorithms used by the users.

In this thesis, we continue the study of ASAs. We contribute two main improvements to the existing literature. First, we formalize a possible method for detecting ASAs involving the manipulation of the state maintained by the subverted algorithm. We describe a model that allows a user who is trying to detect the presence of the subversion to force re-use of the algorithm's maintained state, as could happen when the algorithm is running on a virtual machine. This changes the detectability analysis of several published ASAs, rendering them easily detectable. Second, we describe two modifications to existing ASAs that turn them into asymmetric ASAs, which are more resilient to exploitation by another party who reverse engineers the subverted implementation.

\paragraph{Work prior to \cite{C:BelPatRog14}.} The study of subverting a cryptographic algorithm by changing the implementation to differ from the specification is not new. Termed kleptography, research in this area was initiated by Young and Yung \cite{C:YouYun96}, who did several follow-up works  \cite{EC:YouYun97,FSE:YouYun98,SAC:YouYun04,ACISP:YouYun03}. Their work was inspired by subliminal channels in public-key cryptosystems \cite{EC:Simmons84,C:Desmedt88}, which they then showed could create serious problems. Several authors have studied backdoors in symmetric encryption \cite{FSE:RijPre97,FSE:Paterson99}. Goh, Boneh, Pinkas, and Golle \cite{ISC:GBPG03} studied implementations of TLS/SSL and SSH that provide key recovery capabilities. Schneier, Fredrikson, Kohno, and Ristenpart published a survey of cryptographic subversion in general \cite{EPRINT:SFKR15}.

\paragraph{Algorithm substitution attacks (ASAs).} Suppose a user $\mathcal{U}$ is using a symmetric encryption scheme $\mathsf{SE}$ for encryption of their communications. An attacker (sometimes referred to as Big Brother) is able to exchange the encryption algorithm $\mathsf{SE.Enc}$ for an alternative algorithm $\mathsf{Sub.Enc}$, which we call the subverted algorithm. While using the algorithm $\mathsf{Sub.Enc}$, $\mathcal{U}$ will send a set of ciphertexts. From observation of these ciphertexts, the attacker wants to be able to recover the secret key $k$ used for encryption. If this was the only requirement, an ASA would be trivial: the subverted encryption algorithm could simply output the secret key on any input. However, the attacker would like continuous exploitation of the system, and so wishes for $\mathcal{U}$ to be unaware of the subversion. For this we require an ASA to be undetectable, meaning that $\mathcal{U}$ should not be able to (with black box access) distinguish between  $\mathsf{Sub.Enc}$ and $\mathsf{SE.Enc}$. A minimum requirement for undetectability would be that all (or all but a negligible fraction) of the possible ciphertexts correctly decrypt, but this alone would not be enough. The formal requirement is captured in a detectability game that the user $\mathcal{U}$ plays.

A variety of techniques can be used to create an ASA, but in general an ASA relies on the attacker sharing a key $\overline{k}$ with the subverted algorithm, and requires that $\mathsf{SE.Enc}$ is randomized. Bellare, Paterson, and Rogaway \cite{C:BelPatRog14}, in their seminal paper, presented a technique involving acceptance-rejection on ciphertexts generated by the unsubverted encryption algorithm. A pseudorandom function is evaluated on $\overline{k}$ and a ciphertext, giving a single bit $b$. If the first bit of secret key is equal to $b$, then that ciphertext is returned; otherwise, a new one is computed. Since the attacker knows $\overline{k}$, he can recover the first bit of the secret key $k$ from the ciphertext. Repeating this for each position within the secret key (which the ASA maintains as state) allows for recovery of the whole key. Since $\overline{k}$ is unknown to $\mathcal{U}$, the ciphertexts still appear randomly generated. Hence both key recovery and undetectability are achieved. \cite{C:BelPatRog14} called this the ``biased-ciphertext attack.''

We will discuss other developments in the history of ASAs in \autoref{sec:ASA}.


\section{State resets for detection of ASAs}
In the literature, there has been a tendency towards ensuring that new ASAs are stateless, meaning the subverted algorithm does not depend on any additional data saved between executions. \cite{C:BelPatRog14}, who coined the term ASA, noted that the biased-ciphertext attack they introduced was stateful. They said that, since the attack is stateful, ``a reset of the state will lead to increased detection ability for an observer, but ... this increase does not appear to be enough to lead to actual detection.'' Improving on the results of \cite{C:BelPatRog14}, \cite{CCS:BelJaeKan15} presented a stateless version of the biased-ciphertext attack. They seem to interpret some of the conclusions from \cite{C:BelPatRog14} differently, saying, with reference to the previous work, ``a state reset, as can happen with a reboot or cloning to create a virtual machine, leads, in their attack, to detection.'' They then define a notion of undetectability that necessitates statelessness, and call this \emph{strong undetectability}. As a result of the interpretations and emphasis of \cite{CCS:BelJaeKan15}, as well as the fact that stateless subversions have proven more difficult to develop, later work has often acknowledged that stateless schemes are surely preferable. Authors detailing stateful subversions have spent time justifying that the amount of state that they are maintaining is small, and so more palatable for the adversary to include \cite{BSKC2019,AC:CheHuaYun20}.

This begs a question: how does an adversary against the undetectability of a subversion use state resets to detect the subversion? To our knowledge, this question has not been addressed fully in the literature. The closest example is due to Baek, Susilo, Kim, and Chow \cite{BSKC2019}, who included a simple state reset oracle in their undetectability game, which resets the state to the initial null value. However, as noted by \cite{CCS:BelJaeKan15}, we also wish to consider what happens when the algorithm is running on a virtual machine, where the machine state can be cloned and re-run from the same intermediate point, potentially many times. The simple state reset oracle is therefore insufficient.

\paragraph{Contributions.}
We present a stronger state reset oracle than that used by \cite{BSKC2019}, which is able to reset the state of the ASA to \emph{any} state previously used in the detection game. Under this new definition, we show that ASAs given by Ateniese, Magri, and Venturi \cite{CCS:AteMagVen15} (on signatures), Baek et al. \cite{BSKC2019} (on DSA signatures), and Chen, Huang, and Yung \cite{AC:CheHuaYun20} (on key exchange) are all easily detectable. On the other hand, we show that original biased-ciphertext ASA by \cite{C:BelPatRog14} is actually just as undetectable as the ``upgraded'', stateless version given by \cite{CCS:BelJaeKan15}. Our analysis of the ASA from \cite{C:BelPatRog14} also uses the same game-playing proof framework as used in \cite{CCS:BelJaeKan15}, avoiding the ``coin-injective'' assumption on the encryption scheme that was necessary in \cite{C:BelPatRog14}. We present these results in \autoref{sec:statereset}.

\section{Asymmetric ASAs}
When introducing ASAs, \cite{C:BelPatRog14} also considered the possibility of an asymmetric ASA on symmetric encryption. An \emph{asymmetric} ASA is one where the subverted algorithm uses an \emph{embedded} key that is different from the \emph{extraction} key used for key recovery; for example, the two keys could be a public-private key pair. The motivation for this comes from noticing that the embedded subversion key is not particularly protected. Instead, it is embedded in, for example, malware, distributed to the target. While we assume in this model that the target themselves will not scrutinize the code they are using, some third party might find out about the subversion, and reverse engineer the software to learn the embedded key. The subverter would have a strong incentive to prevent a third party from obtaining the same key recovery capabilities as the subverter. If the embedded key is presumed to be public knowledge, and the ASA remains undetectable, then the subverter is assured that they are the only one capable of exploiting the ASA. In an appendix, \cite{C:BelPatRog14} give the necessary definitional extensions for asymmetric ASAs, and leave the development of an asymmetric ASA as an open problem. Later works considered asymmetric ASAs in certain specific contexts, like on signature schemes and KEMs that satisfy certain conditions \cite{AC:CheHuaYun20,BSKC2019}.

\paragraph{Contributions.}
In this thesis, we will consider two different kinds of asymmetric ASAs. In a \emph{type 1} asymmetric ASA, the subversion is required to be undetectable to an adversary in possession of the embedded subversion key; we call this augmented undetectability. This is the simplest way of thinking about an asymmetric ASA, and the definition that has been used in other literature. In a \emph{type 2} asymmetric ASA, we will instead require that the subversion is only undetectable to an adversary who does not know the embedded subversion key, as in the case of a symmetric ASA, but we also require that a type 2 asymmetric ASA is secure against exploitation (in the sense that the attacker exploits the ASA) by an adversary in possession of the embedded subversion key. This less restrictive requirement is a reflection of the fact that the main goals for an asymmetric ASA (besides recovering the targeted information) are as follows: to ensure that the user of the cryptographic scheme (or some entity with the decision-making authority to halt usage of the cryptographic scheme) being attacked is unaware of the attack, and to ensure that no other entity is able to exploit the ASA to recover the targeted information. While this is accomplished by a type 1 asymmetric ASA (indeed, a type 1 ASA is also a type 2 ASA), our stipulated requirements for a type 2 asymmetric ASA will also suffice. The relaxed requirements allow for more flexibility when designing an ASA, and allows us to create an ASA whose executions take less time.

In \autoref{sec:asymASA}, we modify the ASA of \cite{C:BelPatRog14} to obtain a type 1 asymmetric ASA on symmetric encryption, that is, an ASA undetectable by an adversary who is in possession of the embedded subversion key and is able to use state resets on the encryption scheme. This provides an answer to their open problem explicitly in the case of symmetric encryption. In \autoref{sec:asymASA2} we modify the ASA of \cite{CCS:BelJaeKan15} (which is itself a modification of the ASA from \cite{C:BelPatRog14}) to obtain a type 2 asymmetric ASA on symmetric encryption. To show the advantages of this ASA, we do a thorough analysis of the parameters and techniques the attacker can use in practice to recover the key. We show that our type 2 asymmetric ASA can enable key recovery in practice with a subverted encryption function which runs in less time, making it, in theory, less susceptible to detection by timing.

In order to give a better idea of how these new ASAs compare to other published ASAs, we give a comparison of some basic properties in \autoref{tab:ASAcompare}.

Finally, in \autoref{sec:generalize} we give a generalization of the modifications we made to the above ASAs, in order to apply our results to other cryptographic primitives and security notions. Our results allow for a large class of ASAs to be modified to create type 1 and type 2 asymmetric ASAs. These results apply to any cryptographic primitive, and in the case of the type 2 modification, any game-based notion of security. These results will make it easier for future researchers to evaluate whether their symmetric ASAs can be modified to create asymmetric ASAs.

\begin{table}
\centering
\newcommand{\pie}[1]{%
    \begin{tikzpicture}
    \draw (0,0) circle (3pt);
    \fill (0,3pt) arc[radius = 3pt, start angle= 90, end angle= 90-#1] -- (0,0) -- cycle;
    \end{tikzpicture}%
}
\newcommand{\yes}{{\pie{360}}}
\newcommand{\no}{{\pie{0}}}
\NewDocumentCommand{\rotX}{O{-45} O{1em} m}{\makebox[#2][r]{\rotatebox[origin=r]{#1}{#3}}}%
\vspace{4pt}
\scalebox{0.89}{
\begin{tabular}{p{9.5cm} cccccc}
\toprule
& \rotX{\cite{C:BelPatRog14}} & \rotX{\cite{CCS:BelJaeKan15}} & \rotX{\cite{BSKC2019}} & \rotX{\cite{AC:CheHuaYun20}} & \rotX{Our type 1} & \rotX{Our type 2} \\
\midrule
Asymmetric 
& \no & \no & \yes & \yes & \yes & \yes \\
\midrule
\multicolumn{7}{l}{\textit{No state reset}} \\
\midrule
Undetectable vs. regular adversary
& \yes & \yes & \yes & \yes & \yes & \yes \\
Undetectable vs. augmented adversary
& \no & \no & \yes & \yes & \yes & \no \\
Secure vs. augmented adversary 
& \no & \no & \yes & \yes & \yes & \yes \\
\midrule
\multicolumn{7}{l}{\textit{State reset}} \\
\midrule
Undetectable vs. regular adversary (SRDET)
& \yes & \yes & \no & \no & \yes & \yes \\
Undetectable vs. augmented adversary (ASRDET)
& \no & \no & \no & \no & \yes & \no \\
Secure vs. augmented adversary 
& \no & \no & \yes & \yes & \yes & \yes \\
\midrule
Intercepted transmissions needed
& $128$ & $\approx 700$ & $3$ & $2$ & $400$ & $\approx 2600$ \\
Runtime multiplier
& $\ge 7$ & $\ge 2$ & $\approx 1$ & $\approx 1$ & $\ge 9$ & $\ge 2$ \\
\bottomrule
\end{tabular}
} %\scalebox
\caption[Comparison of properties of various ASAs]{Comparison of properties of various ASAs. An augmented adversary refers to an adversary in possession of the embedded subversion key. If applicable, $|k|=128$.} \label{tab:ASAcompare}
\end{table}

